# Testing

In this post I would like to summarize important concepts and tips about testing.

These are the three types I write usually:

-   Unit tests: Tests know the details of the code.
-   Acceptance tests: Tests do not know the details of the code.
-   Integration tests: Tests about how two separate systems integrate.

The tests are part of the CI (continuous integration) pipeline (using Jenkins for example), so I am aware of tests failing and I can fix the code before deploying in a production environment.

In a CD (continuous deployment) pipeline, if the tests fail, the deploy is automatically stopped, otherwise the code is automatically deployed. The commit is the trigger.

## Why should I write tests?

-   I prove that our software works.
-   I can reproduce very concrete complex use cases.
-   I avoid bugs (saving money).
-   I refactor with peace of mind.
-   I automate processes like CI.
-   I explore functionality (documentation).

## An example of unit test

In this case we test units of code within the same module. We do not execute anything belonging to the infrastructure layer nor I/O. So usually we test methods or classes where given some inputs we get some outputs. All the infrastructure dependencies are mocked.

```php
public function testNormalNumbersReturnSameNumber ()
{
    $this->assertEquals($this->fizzBuzz->run(1), 1);
    $this->assertEquals($this->fizzBuzz->run(2), 2);
    $this->assertEquals($this->fizzBuzz->run(4), 4);
}
```

## An example of integration test

This time we have I/O and state. In back end we test mainly persistence, like public APIs, memory or databases. So in this case we have a repository interface and its implementation.

```php
interface PostRepository
{
    public function save(Post $post): void;
    public function search(PostId $postId): ?Post;
}

final class PostRepositoryMySql implements PostRepository
{
    public function save(Post $post): void
    {
        // ...
    }
    public function search(PostId $postId): ?Post
    {
        // ...
    }
}
```

Then we test happy paths (save and search is going to work)

```php
public class PostRepositoryMySqlTest
{
    /**
     * @var PostRepositoryMySql
     */
    private $postRepositoryMysql;
    public function setUp()
    {
        $this->postRepositoryMysql = new PostRepositoryMySql();
    }
    public function itShouldSaveAPost()
    {
        $post = new Post('My new post on testing');
        $this->postRepositoryMysql->save($post);
    }
    public function itShouldFindAnExistingPost()
    {
        $post = new Post('My new post on testing');
        $this->postRepositoryMysql->save($post);
        $this->assertSimilar($post, $this->postRepositoryMysql->search($post->id()));
    }
}
```

We can imagine many other interesting cases not so happy, like testing what it should happen if the post is not found.

Integration tests must be completely independents, so the Post created within the*save test* won't be used within the _search test_. In this way there are not dependencies between tests and if someday I delete or update the test saving the post object, the rest of the suite is going to work as expected. We can achieve that systematically having a "before" method to flush the memory, cleaning the database or whatever persistence mechanism I am using. Also, in that manner, we can execute our tests concurrently.

Having said that, and [according to Martin Fowler](https://martinfowler.com/bliki/IntegrationTest.html):

> Integration tests determine if independently developed units of software work correctly when they are connected to each other.
>
> _Martin Fowler_

So we do not necessarily test database integration. We can imagine many other possibilities, even though professionally speaking, this is the case I have found in most of the cases.

## An example of acceptance test

Theses tests are made from the point of view of the user. And the input should be the same: if the user triggers the code by filling a form, we should fill and send the form in our test. If the user makes an http call, we should make a request to start the test. Also the scope of the tests is wide and we should have the same infrastructure of the production environment.

There are frameworks to facilitate this kind of tests. I am using [Robot Framework](https://robotframework.org/) lately but I also implemented [Behat](https://docs.behat.org/en/latest/) in the past and I loved it.

Both have some in common: _Gherkin_. So the first step is to define the test using Gherkin and then we can implement the test using the framework machinery.

This is a beautiful example from the documentation page of Behat, I think is pretty auto explanatory:

```gherkin
Feature: Product basket
  In order to buy products
  As a customer
  I need to be able to put interesting products into a basket
  Rules:
  - VAT is 20%
  - Delivery for basket under 'a310 is 'a33
  - Delivery for basket over 'a310 is 'a32
  Scenario: Buying a single product under 'a310
    Given there is a "Sith Lord Lightsaber", which costs 'a35
    When I add the "Sith Lord Lightsaber" to the basket
    Then I should have 1 product in the basket
    And the overall basket price should be 'a39
  Scenario: Buying a single product over 'a310
    Given there is a "Sith Lord Lightsaber", which costs 'a315
    When I add the "Sith Lord Lightsaber" to the basket
    Then I should have 1 product in the basket
    And the overall basket price should be 'a320
  Scenario: Buying two products over 'a310
    Given there is a "Sith Lord Lightsaber", which costs 'a310
    And there is a "Jedi Lightsaber", which costs 'a35
    When I add the "Sith Lord Lightsaber" to the basket
    And I add the "Jedi Lightsaber" to the basket
    Then I should have 2 products in the basket
    And the overall basket price should be 'a320
```

Each of theses scenarios must be implemented using real code obviously. Behat maps this sentences to methods in a PHP class. The beauty of acceptance tests is from my point of view that you get tests but also a documentation quite expressive yet concise of what your application is capable of and under what circumstances.

Acceptance tests do not check if some concrete row has been inserted or if some event has been published (we have integration tests for that). Usually, from the point of view of the user, all they get could be a http response 201 for instance, but the client does not really know if the put or post request has worked, specially in a CQRS architecture.

## Subject under test

The "unit" in Unit tests does not necessarily mean a class or a method. This is not a 1 to 1 relation. If the unit is too close to the implementation details, any change of the code could break the test. If we refactor the code, the tests should not be broken and also, the tests should change only if the business logic changes.

A test suite is going to cover each entry point: the use cases, but knowing that the limit is represented by the interfaces of the domain (I am using terms from ports and adapters architecture), which means that infrastructure layer is not the target of unit tests.

However the Integration Tests have a larger unit because it also covers some other module, how module X behaves when interacting with model Y. An example would be looking for some expectation directly in the database right after executing some piece of code.

Finally Acceptance Tests are going to cover the whole flow. The entry point is the communication protocol used by our clients. Anything else is black box.

## The test pyramid

It is usually accepted that most of the tests written should be unit tests while integration and acceptance tests, being slow and expensive should be limited to very useful cases like critical pieces of the code.
I think the pyramid will become a cylinder in the next years.

## Builder Pattern for tests

This is a very dummy example of builder pattern within a test. The elements are a _Card_ class, a _CardBuilder_ class and the _CardTest_ class. Some advantages of this approach are:

-   We have only one place where a Card is created for testing. If one day the constructor changes, only one place needs to be changed.
-   The test is more semantic, more meaning as we read the configuration (the name of the method _withProgram_).
-   The test itself puts an accent on the state which is relevant for the given spec. In that case, the _program_ attribute.

```php
<?php
declare(strict_types=1);

final class Card
{
    private $id;
    private $program;
    public function __construct(string $id, string $program)
    {
        $this->id = $id;
        $this->program = $program;
    }
    public function canBeOverdrawn(): bool
    {
        return $this->program === 'PROGRAM';
    }
}

final class CardBuilder
{
    private $id;
    private $program;

    public function __construct()
    {
        $this->id = 'ID';
        $this->program = 'PROGRAM';
    }
    public function withProgram(string $program): self
    {
        $this->program = $program;
        return $this;
    }
    public function build(): Card
    {
        return new Card($this->id, $this->program);
    }
}

final class CardTest
{
    public function testCardCanOverdrawWithProgram()
    {
        $card = (new CardBuilder())->withProgram('PROGRAM')->build();
        static::assertTrue($card->canBeOverdrawn());
    }
}
```

Sometimes, especially if the object has many attributes, the builder pattern could be to verbose: imagine a long list of linked fluent methods.

In this case we can use the Object Mother pattern. We encapsulate not only the instantiation of the Object, but also the configuration of the object. In the test I have now something like this:

```php
public  function  testCardCanOverdrawWithProgram()
{
    $card  = CardMother::withProgram('PROGRAM');
    static::assertTrue($card->canBeOverdrawn());
}
```

Which is way more readable and concise thanks to the named constructor _withProgram_.

## Test doubles

Fakes: A fake implementation of an interface in memory. It could be functional (not necessarily a dummy object). It obliges the developer to create more code and maintain it. A fake does not make verifications on the state or methods called.

Stubs: A fake with predefined values. It helps modeling the particular case we would like to test.

Mocks: We define the objects to be returned and the methods called so the mock allows to verify the behavior and collaboration between the SUT and the mocked objects.

On daily basis I use mocks, they let me do whatever I like and I do not have to code and maintain extra code (fakes and stubs).

## Miscellaneous

-   Keep tests folder structure similar to source code structure.
-   Apply good practices also while writing tests code. As Uncle Bob said: "SRP for tests: one broken requirement should only break one test".
-   Given / When / Then pattern is a good way to write semantic tests.
-   ATDD seems very nice isn't it? Acceptance tests + TDD outside-in in the same red-green-blue cycle.
